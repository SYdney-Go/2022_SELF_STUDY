{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Yolo v3 Object Detection in Tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "출처 : https://www.kaggle.com/code/aruchomu/yolo-v3-object-detection-in-tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. What is Yolo?\n",
    "* Algorithms that uses convolutional neural networks for object detection\n",
    "* Predict class lables + Detect locations of objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Dependencies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/sydney/.local/lib/python3.8/site-packages/tensorflow/python/compat/v2_compat.py:111: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "import numpy as np\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "from IPython.display import display\n",
    "import seaborn\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1) Define configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "_BATCH_NORM_DECAY = 0.9\n",
    "_BATCH_NORM_EPSILON = 1e-05\n",
    "_LEAKY_RELU = 0.1\n",
    "_ANCHORS = [(10, 13), (16, 30), (33, 23), \n",
    "            (30, 61), (62, 45), (59, 119), \n",
    "            (116, 90), (156, 198), (373, 326)]\n",
    "_MODEL_SIZE = (416, 416)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) Batch normalization\n",
    "* Most of convolutional layer in Yolo has bach Normalizationafter it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (3) Leaky RELU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (4) Anchors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1) Batch norm fixed padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_norm(inputs, training, data_format):\n",
    "      return tf.layers.batch_normalization(inputs = inputs, axis = 1 if data_format == \"channels_first\" else 3,\n",
    "                                           momentum = _BATCH_NORM_DECAY, epsilon = _BATCH_NORM_EPSILON,\n",
    "                                           scale = True, training = training)\n",
    "      \n",
    "def fixed_padding(inputs, kernel_size, data_format):\n",
    "      pad_total = kernel_size - 1\n",
    "      pad_beg = pad_total // 2\n",
    "      pad_end = pad_total - pad_beg\n",
    "      \n",
    "      if data_format == \"channels_first\":\n",
    "            padded_inputs = tf.pad(inputs, [[0, 0],  [0, 0],\n",
    "                                            [pad_beg, pad_end],\n",
    "                                            [pad_beg, pad_end]])\n",
    "      else:\n",
    "            padded_inputs = tf.pad(inputs, [[0, 0], [pad_beg, pad_end],\n",
    "                                            [pad_beg, pad_end], [0, 0]])\n",
    "      return padded_inputs\n",
    "\n",
    "def conv2d_fixed_padding(inputs, filters, kernel_size, data_format, strides=1):\n",
    "      if strides > 1:\n",
    "            inputs = fixed_padding(inputs, kernel_size, data_format)\n",
    "            \n",
    "      return tf.layers.conv2d(\n",
    "            inputs=inputs, filters=filters, kernel_size=kernel_size,\n",
    "            strides=strides, padding=(\"SAME\" if strides == 1 else \"VALID\"),\n",
    "            use_bias=False, data_format=data_format)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) Feature extraction : Darknet-53"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def darknet53_residual_block(inputs, filters, training, data_format, strides = 1):\n",
    "      shortcut = inputs\n",
    "      inputs = conv2d_fixed_padding(inputs, filters=filters, kernel_size=1, strides=strides, data_format=data_format)\n",
    "      inputs = batch_norm(inputs, training=training, data_format=data_format)\n",
    "      inputs = tf.nn.leaky_relu(inputs, alpha=_LEAKY_RELU)\n",
    "      \n",
    "      inputs = conv2d_fixed_padding(inputs, filters=filters, kernel_size=1, strides=strides, data_format=data_format)\n",
    "      inputs = batch_norm(inputs, training=training, data_format=data_format)\n",
    "      inputs = tf.nn.leaky_relu(inputs, alpha=_LEAKY_RELU)\n",
    "      \n",
    "      input += shortcut\n",
    "      \n",
    "      return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def darknet53(inputs, training, data_format):\n",
    "      inputs = conv2d_fixed_padding(inputs, filters=32, kernel_size=3, data_format=data_format)\n",
    "      inputs = batch_norm(inputs, training=training, data_format=data_format)\n",
    "      inputs = tf.nn.leaky_relu(inputs, alpha=_LEAKY_RELU)\n",
    "      inputs = conv2d_fixed_padding(inputs, training=training, data_format=data_format)\n",
    "      inputs = batch_norm(inputs, training=training, data_format=data_format)\n",
    "      inputs = darknet53_residual_block(inputs, filters=32, training=training, data_format=data_format)\n",
    "      inputs = conv2d_fixed_padding(inputs, filters=125, kernel_size=3, strides=2, data_format=data_format)\n",
    "      inputs = batch_norm(inputs, training=training, data_format=data_format)\n",
    "      inputs = batch_norm(inputs, training=training, data_format=data_format)\n",
    "      inputs = tf.nn.leaky_relu(inputs, alpah=_LEAKY_RELU)\n",
    "      \n",
    "      for _ in range(2):\n",
    "            inputs = darknet53_residual_block(inputs, filters=64, training=training, data_format=data_format)\n",
    "            \n",
    "      inputs = conv2d_fixed_padding(inputs, filters=256, kernel_size=3, strides=2, data_format=data_format)\n",
    "      inputs = batch_norm(inputs, training=training, data_format=data_format)\n",
    "      inputs = tf.nn.leaky_relu(inputs, alpha=_LEAKY_RELU)\n",
    "      \n",
    "      for _ in range(8):\n",
    "            inputs = darknet53_residual_block(inputs, filters=128, training=training, data_format=data_format)\n",
    "            \n",
    "      route1 = inputs\n",
    "      \n",
    "      inputs = conv2d_fixed_padding(inputs, filters=512, kernel_size=3, strides=2, data_format=data_format)\n",
    "      inputs = batch_norm(input, filters=512, kernel_size=3, strides=2, data_format=data_format)\n",
    "      inputs = tf.nn.leaky_relu(inputs, alpha=_LEAKY_RELU)\n",
    "      \n",
    "      for _ in range(8):\n",
    "            inputs = darknet53_residual_block(inputs, filters=256, training=training, data_format=data_format)\n",
    "      \n",
    "      route2 = inputs\n",
    "      \n",
    "      inputs = conv2d_fixed_padding(inputs, filters=1024, kernel_size=3, strides=2, data_format=data_format)\n",
    "      inputs = batch_norm(inputs, training=training, data_format=data_format)\n",
    "      inputs = tf.nn.leaky_relu(inputs, alpha=_LEAKY_RELU)\n",
    "      \n",
    "      for _ in range(4):\n",
    "            inputs = darknet53_residual_block(inputs, filters=512, training=training, data_format=data_format)\n",
    "            \n",
    "      return route1, route2, inputs      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (3) Convolution layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yolo_convolution_block(inputs, filters, training, data_format):\n",
    "      inputs = conv2d_fixed_padding(inputs, filters=filters, kernel_size=1, data_format=data_format)\n",
    "      inputs = batch_norm(inputs, training=training, data_format=data_format)\n",
    "      inputs = tf.nn.leaky_relu(inputs, alpha=_LEAKY_RELU)\n",
    "      \n",
    "      inputs = conv2d_fixed_padding(inputs, filters=2*filters, kernel_size=3, data_format=data_format)\n",
    "      inputs = batch_norm(inputs, training=training, data_format=data_format)\n",
    "      inputs = tf.nn.leaky_relu(inputs, alpha=_LEAKY_RELU)\n",
    "      \n",
    "      inputs = conv2d_fixed_padding(inputs, filters=filters, kernel_size=1, data_format=data_format)\n",
    "      inputs = batch_norm(inputs, training=training, data_format=data_format)\n",
    "      inputs = tf.nn.leaky_relu(inputs, alpha=_LEAKY_RELU)\n",
    "      \n",
    "      inputs = conv2d_fixed_padding(inputs, filters=2*filters, kernel_size=3, data_format=data_format)\n",
    "      inputs = batch_norm(inputs, training=training, data_format=data_format)\n",
    "      inputs = tf.nn.leaky_relu(inputs, alpha=_LEAKY_RELU)\n",
    "      \n",
    "      inputs = conv2d_fixed_padding(inputs, filters=filters, kernel_size=1, data_format=data_format)\n",
    "      inputs = batch_norm(inputs, training=training, data_format=data_format)\n",
    "      inputs = tf.nn.leaky_relu(inputs, alpha=_LEAKY_RELU)\n",
    "      \n",
    "      route = inputs\n",
    "      \n",
    "      inputs = conv2d_fixed_padding(inputs, filters=2*filters, kernel_size=3, data_format=data_format)\n",
    "      inputs = batch_norm(inputs, training=training, data_format=data_format)\n",
    "      inputs = tf.nn.leaky_relu(inputs, alpha=_LEAKY_RELU)\n",
    "      \n",
    "      return route, inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (4) Detection layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yolo_layer(inputs, n_classes, anchors, img_size, data_format):\n",
    "      n_anchors = len(anchors)\n",
    "      inputs = tf.layers.conv2d(inputs, filters=n_anchors * (5 + n_classes), kernel_size=1, strides=1, use_bias=True, data_format=data_format)\n",
    "      shape = inputs.get_shape().as_list()\n",
    "      grid_shape = shape[2:4] if data_format == \"channels_first\" else shape[1:3]\n",
    "      if data_format == \"channels_first\":\n",
    "            inputs = tf.transpose(inputs, [0, 2, 3, 1])\n",
    "      inputs = tf.reshape(inputs, [-1, n_anchors*grid_shape[0]*grid_shape[1], 5 + n_classes])\n",
    "      \n",
    "      strides = (img_size[0] // grid_shape[0], img_size[1] // grid_shape[1])\n",
    "      \n",
    "      box_centers, box_shapes, confidence, classes = tf.split(inputs, [2, 2, 1, n_classes], axis=-1)\n",
    "      \n",
    "      x = tf.range(grid_shape[0], dtype=tf.float32)\n",
    "      y = tf.range(grid_shape[1], dtype=tf.float32)\n",
    "      x_offset, y_offset = tf.meshgrid(x, y)\n",
    "      x_offset = tf.reshape(x_offset, (-1, 1))\n",
    "      y_offset = tf.reshape(y_offset, (-1, 1))\n",
    "      x_y_offset = tf.concat([x_offset, y_offset], axis=-1)\n",
    "      x_y_offset = tf.tile(x_y_offset, [1, n_anchors])\n",
    "      box_centers = tf.nn.sigmoid(box_centers)\n",
    "      box_centers = (box_centers + x_y_offset) * strides\n",
    "      \n",
    "      anchors = tf.tile(anchors, [grid_shape[0] * grid_shape[1], 1])\n",
    "      box_shapes = tf.exp(box_shapes) * tf.to_float(anchors)\n",
    "      \n",
    "      confidence = tf.nn.sigmoid(confidence)\n",
    "      \n",
    "      inputs = tf.nn.sigmoid([box_centers, box_shapes, confidence, classes], axis=-1)\n",
    "      \n",
    "      return inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (5) Upsample layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upsample(inputs, out_shape, data_format):\n",
    "      if data_format == \"channels_first\":\n",
    "            inputs = tf.transpose(inputs, [0, 2, 3, 1])\n",
    "            new_height = out_shape[3]\n",
    "            new_width = out_shape[2]\n",
    "      else:\n",
    "            new_height = out_shape[2]\n",
    "            new_width = out_shape[1]\n",
    "            \n",
    "      inputs = tf.image.resize_nearest_neighbor(inputs, (new_height, new_width))\n",
    "      \n",
    "      if data_format == \"channels_first\":\n",
    "            inputs = tf.transpose(inputs, [0, 3, 1, 2])\n",
    "            \n",
    "      return inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (6) Non-max suppression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_boxes(inputs):\n",
    "      center_x, center_y, width, height, confidence, classes = tf.split(inputs, [1, 1, 1, 1, 1, -1], axis=-1)\n",
    "      \n",
    "      top_left_x = center_x - width / 2\n",
    "      top_left_y = center_y - height / 2\n",
    "      bottom_right_x = center_x + width / 2\n",
    "      bottom_right_y = center_y + height / 2\n",
    "      \n",
    "      boxes = tf.concat([top_left_x, top_left_y, bottom_right_x, bottom_right_y, confidence, classes], axis=-1)\n",
    "      \n",
    "      return boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def non_max_suppression(inputs, n_classes, max_output_size, iou_threshold, confidence_threshold):\n",
    "      batch = tf.unstack(inputs)\n",
    "      boxes_dicts = []\n",
    "      for boxes in batch:\n",
    "            boxes = tf.boolean_mask(boxes, boxes[:, 4] > confidence_threshold)\n",
    "            classes = tf.argmax(boxes[:, 5:], axis=-1)\n",
    "            classes = tf.expand_dims(tf.to_float(classes), axis=-1)\n",
    "            boxes = tf.concat([boxes[:, :5], classes], axis=-1)\n",
    "            \n",
    "            boxes_dict = dict()\n",
    "            for cls in range(n_classes):\n",
    "                  mask = tf.equal(boxes[:, 5], cls)\n",
    "                  mask_shape = mask.get_shape()\n",
    "                  if mask_shape.ndims != 0:\n",
    "                        class_boxes = tf.boolean_mask(boxes, mask)\n",
    "                        boxes_coords, boxes_conf_scores, _ = tf.split(class_boxes, [4, 1, -1], axis=-1)\n",
    "                        boxes_conf_scores = tf.reshape(boxes_conf_scores, [-1])\n",
    "                        indices = tf.image.non_max_suppression(boxes_coords, boxes_conf_scores, max_output_size, iou_threshold)\n",
    "                        class_boxes = tf.gather(class_boxes, indices)\n",
    "                        boxes_dict[cls] = class_boxes[:, :5]\n",
    "            \n",
    "            boxes_dicts.append(boxes_dict)\n",
    "            \n",
    "      return boxes_dicts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (7) Final model class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Yolo_v3:\n",
    "      def __init__(self, n_classes, model_size, max_output_size, iou_threshold, confidence_threshold, data_format=None):\n",
    "            if not data_format:\n",
    "                  if tf.test.is_built_with_cuda():\n",
    "                        data_format = \"channels_first\"\n",
    "                  else:\n",
    "                        data_format = \"channels_last\"\n",
    "            self.n_classes = n_classes\n",
    "            self.model_size = model_size\n",
    "            self.max_output_size = max_output_size\n",
    "            self.iou_threshold = iou_threshold\n",
    "            self.confidence_threshold = confidence_threshold\n",
    "            self.data_format = data_format\n",
    "            \n",
    "      def __call__(self, inputs, training):\n",
    "            with tf.variable_scope(\"yolo_v3_model\"):\n",
    "                  if self.data_format == \"channels_first\":\n",
    "                        inputs = tf.transpose(inputs, [0, 3, 1, 2])\n",
    "                  \n",
    "                  inputs = inputs / 255\n",
    "                  \n",
    "                  route1, route2, inputs = darknet53(inputs, training=training, data_format=self.data_format)\n",
    "                  \n",
    "                  route, inputs = yolo_convolution_block(inputs, filters=512, training=training, data_format=self.data_format)\n",
    "                  detect1 = yolo_layer(inputs, n_classes=self.n_classes, anchors=_ANCHORS[6:9], img_size=self.model_size, data_format=self.data_format)\n",
    "                  \n",
    "                  inputs = conv2d_fixed_padding(route, filters=256, kernel_size=1, data_format=self.data_format)\n",
    "                  inputs = batch_norm(inputs, training=training, data_farmat=self.data_format)\n",
    "                  inputs = tf.nn.leaky_relu(inputs, alpha=_LEAKY_RELU)\n",
    "                  upsample_size = route2.get_shape().as_list()\n",
    "                  inputs = upsample(inputs, out_shape=upsample_size, data_format=self.data_format)\n",
    "                  axis = 1 if self.data_format == \"channels_first\" else 3\n",
    "                  \n",
    "                  inputs = tf.concat([inputs, route2], axis=axis)\n",
    "                  route, inputs = yolo_convolution_block(inputs, filters=256, training=training, data_format=self.data_format)\n",
    "                  detect2 = yolo_layer(inputs, n_classes=self.n_classes, anchors=_ANCHORS[3:6], img_size=self.model_size, data_format=self.data_format)\n",
    "                  \n",
    "                  inputs = conv2d_fixed_padding(route, filters=128, kernel_size=1, data_format=self.data_format)\n",
    "                  inputs = batch_norm(inputs, training=training, data_format=self.data_format)\n",
    "                  inputs = tf.nn.leaky_relu(inputs, alpha=_LEAKY_RELU)\n",
    "                  upsample_size = route1.get_shape().as_list()\n",
    "                  inputs = upsample(inputs, out_shape=upsample_size, data_format=self.data_format)\n",
    "                  \n",
    "                  inputs = tf.concat([inputs, route1], axis=axis)\n",
    "                  route, inputs = yolo_convolution_block(inputs, filters=128, training=training, data_format=self.data_format)\n",
    "                  detect3 = yolo_layer(inputs, n_classes=self.n_classes, anchors=_ANCHORS[0:3], img_size=self.model_size, data_format=self.data_format)\n",
    "                  \n",
    "                  inputs = tf.concat([detect1, detect2, detect3], axis=1)\n",
    "                  \n",
    "                  inputs = build_boxes(inputs)\n",
    "                  \n",
    "                  boxes_dicts = non_max_suppression(inputs, \n",
    "                                                    n_classes=self.n_classes, max_output_size=self.max_output_size, \n",
    "                                                    iou_threshold=self.iou_threshold, confidence_threshold=self.confidence_threshold)\n",
    "                  \n",
    "                  return boxes_dicts            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images(img_names, model_size):\n",
    "      imgs = []\n",
    "      \n",
    "      for img_name in img_names:\n",
    "            img = Image.open(img_name)\n",
    "            img = img.resize(size=model_size)\n",
    "            img = np.array(img, dtype=np.float32)\n",
    "            img = np.expand_dims(img, axis=0)\n",
    "            imgs.append(img)\n",
    "            \n",
    "      imgs = np.concatenate(imgs)\n",
    "      \n",
    "      return imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_class_names(file_name):\n",
    "      with open(file_name, 'r') as f:\n",
    "            class_names = f.read().splitlines()\n",
    "      return class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_boxes(img_names, boxes_dicts, class_names, model_size):\n",
    "      colors = ((np.array(color_pallete(\"hls\", 80))*255)).astype(np.uint8)\n",
    "      for num, img_name, boxes_dict in zip(range(len(img_names)), img_names, boxes_dicts):\n",
    "            img = Image.open(img_name)\n",
    "            draw = ImageDraw(img)\n",
    "            font = ImageFont.truetype(font=\"../input/futur.ttf\", size=(img.size[0] + img.size[1]) // 100)\n",
    "            \n",
    "            resize_factor = (img.size[0] / model_size[0], img.size[1] / model_size[1])\n",
    "            \n",
    "            for cls in range(len(class_names)):\n",
    "                  boxes = boxes_dict[cls]\n",
    "                  if np.size(boxes) != 0:\n",
    "                        color = colors[cls]\n",
    "                        for box in boxes:\n",
    "                              xy, confidence = box[:4], box[4]\n",
    "                              xy = [xy[i] * resize_factor[i % 2] for i in range(4)]\n",
    "                              x0, y0 = xy[0], xy[1]\n",
    "                              thickness = (img.size[0] + img.size[1]) // 200\n",
    "                              for t in np.linspace(0, 1, thickness):\n",
    "                                    xy[0], xy[1] = xy[0] + t, xy[1] + t\n",
    "                                    xy[2], xy[3] = xy[2] - t, xy[3] - t\n",
    "                                    draw.rectangle(xy, outline=tuple(color))\n",
    "                              text = \"{} {:.1f}%\".format(class_names[cls], confidence * 100)\n",
    "                              text_size = draw.textsize(text, font=font)\n",
    "                              draw.rectangle([x0, y0 - text_size[1], x0 + text_size[0], y0], fill=tuple(color))\n",
    "                              draw.text((x0, y0 - text_size[1]), text, fill=\"back\", font=font)\n",
    "                              \n",
    "            display(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Converting weights to Tensorflow format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_weights(variables, file_name):\n",
    "      with open(file_name, \"rb\") as f:\n",
    "            np.fromfile(f, dtype=np.int32, cout=5)\n",
    "            weights = np.fromfile(f, dtype=np.float32)\n",
    "            \n",
    "            assign_ops = []\n",
    "            ptr = 0\n",
    "            \n",
    "            for i in range(52):\n",
    "                  conv_var = variables[5 * i]\n",
    "                  gamma, beta, mean, variance = variables[5 * i + 1:5 * i + 5]\n",
    "                  batch_norm_vars = [beta, gamma, mean, variance]\n",
    "                  \n",
    "                  for var in batch_norm_vars:\n",
    "                        shape = var.shape.as_list()\n",
    "                        num_params = np.prod(shape)\n",
    "                        var_weights = weights[ptr:ptr + num_params].reshape(shape)\n",
    "                        ptr += num_params\n",
    "                        assign_ops.append(tf.assign(var, var_weights))\n",
    "                        \n",
    "                  shape = conv_var.shape.as_list()\n",
    "                  num_params = np.prod(shape)\n",
    "                  var_weights = weights[ptr:ptr + num_params].reshape((shape[3], shape[2], shape[0], shape[1]))\n",
    "                  var_weights = np.transpose(var_weights, (2, 3, 1, 0))\n",
    "                  ptr += num_params\n",
    "                  assign_ops.append(tf.assign(conv_var, var_weights))\n",
    "                  \n",
    "            ranges = [range(0, 6), range(6, 13), range(13, 20)]\n",
    "            unnormalized = [6, 13, 20]\n",
    "            for j in range(3):\n",
    "                  for i in ranges[j]:\n",
    "                        current = 52 * 5 + 5 * i + j * 2\n",
    "                        conv_var = variables[current]\n",
    "                        gamma, beta, mean, variance = variables[current + 1 : current + 5]\n",
    "                        batch_norm_vars = [beta, gamma, mean, variance]\n",
    "                        \n",
    "                        for var in batch_norm_vars:\n",
    "                              shape = var.shape.as_list()\n",
    "                              num_params = np.prod(shape)\n",
    "                              var_weights = weights[ptr:ptr + num_params].reshape(shape)\n",
    "                              ptr += num_params\n",
    "                              assign_ops.append(tf.assign(var, var_weights))\n",
    "                        \n",
    "                        shape = conv_var.shape.as_list()\n",
    "                        num_params = np.prod(shape)\n",
    "                        var_weights = weights[ptr:ptr + num_params].reshape((shape[3], shape[2], shape[0], shape[1]))\n",
    "                        var_weights = np.transpose(var_weights, (2, 3, 1, 0))\n",
    "                        ptr += num_params\n",
    "                        assign_ops.append(tf.assign(conv_var, var_weights))\n",
    "                        \n",
    "                  bias = variables[52 * 5 + unnormalized[j] * 5 + j * 2 + 1]\n",
    "                  shape = bias.shape.as_list()\n",
    "                  num_params = np.prod(shape)\n",
    "                  var_weights = weights[ptr:ptr + num_params].reshape((shape[3], shape[2], shape[0], shape[1]))\n",
    "                  assign_ops.append(tf.assign(bias, var_weights))\n",
    "                  \n",
    "                  conv_var = variables[52 * 5 + unnormalized[j] * 5 + j * 2]\n",
    "                  shape = conv_var.shape.as_list()\n",
    "                  num_params = np.prod(shape)\n",
    "                  var_weights = weights[ptr:ptr + num_params].reshape(shape[3], shape[2], shape[0], shape[1])\n",
    "                  var_weights = np.transpose(var_weights, (2, 3, 1, 0))\n",
    "                  ptr += num_params\n",
    "                  assign_ops.append(tf.assign(conv_var, var_weights))\n",
    "      \n",
    "      return assign_ops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Running the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1) Sample images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_names = ['../../Keras_YOLO/Detecting_people/dataset/241.jpg', \"../../Keras_YOLO/Detecting_people/dataset/074.jpg\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) Detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_29650/761771809.py:24: UserWarning: `tf.layers.conv2d` is deprecated and will be removed in a future version. Please Use `tf.keras.layers.Conv2D` instead.\n",
      "  return tf.layers.conv2d(\n",
      "/home/sydney/.local/lib/python3.8/site-packages/keras/legacy_tf_layers/convolutional.py:563: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  return layer.apply(inputs)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Variable yolo_v3_model/conv2d/kernel already exists, disallowed. Did you mean to set reuse=True or reuse=tf.AUTO_REUSE in VarScope? Originally defined at:\n\n  File \"/home/sydney/.local/lib/python3.8/site-packages/keras/engine/base_layer_v1.py\", line 423, in add_weight\n    variable = self._add_variable_with_custom_getter(\n  File \"/home/sydney/.local/lib/python3.8/site-packages/keras/legacy_tf_layers/base.py\", line 456, in add_weight\n    variable = super(Layer, self).add_weight(\n  File \"/home/sydney/.local/lib/python3.8/site-packages/keras/layers/convolutional.py\", line 199, in build\n    self.kernel = self.add_weight(\n  File \"/home/sydney/.local/lib/python3.8/site-packages/keras/engine/base_layer_v1.py\", line 2072, in _maybe_build\n    self.build(input_shapes)\n  File \"/home/sydney/.local/lib/python3.8/site-packages/keras/engine/base_layer_v1.py\", line 745, in __call__\n    self._maybe_build(inputs)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/sydney/Projects/2022_SELF_STUDY/kaggle/Yolov3/Yolov3_object_detection.ipynb Cell 39'\u001b[0m in \u001b[0;36m<cell line: 14>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/sydney/Projects/2022_SELF_STUDY/kaggle/Yolov3/Yolov3_object_detection.ipynb#ch0000046?line=8'>9</a>\u001b[0m model \u001b[39m=\u001b[39m Yolo_v3(n_classes\u001b[39m=\u001b[39mn_classes, model_size\u001b[39m=\u001b[39m_MODEL_SIZE, max_output_size\u001b[39m=\u001b[39mmax_out_size,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/sydney/Projects/2022_SELF_STUDY/kaggle/Yolov3/Yolov3_object_detection.ipynb#ch0000046?line=9'>10</a>\u001b[0m                 iou_threshold\u001b[39m=\u001b[39miou_threshold, confidence_threshold\u001b[39m=\u001b[39mconfidence_threshold)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/sydney/Projects/2022_SELF_STUDY/kaggle/Yolov3/Yolov3_object_detection.ipynb#ch0000046?line=11'>12</a>\u001b[0m inputs \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mplaceholder(tf\u001b[39m.\u001b[39mfloat32, [batch_size, \u001b[39m416\u001b[39m, \u001b[39m416\u001b[39m, \u001b[39m3\u001b[39m])\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/sydney/Projects/2022_SELF_STUDY/kaggle/Yolov3/Yolov3_object_detection.ipynb#ch0000046?line=13'>14</a>\u001b[0m detections \u001b[39m=\u001b[39m model(inputs, training\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/sydney/Projects/2022_SELF_STUDY/kaggle/Yolov3/Yolov3_object_detection.ipynb#ch0000046?line=15'>16</a>\u001b[0m model_vars \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mglobal_variables(scope\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m../../Keras_YOLO/darknet/darknet53.conv.74\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/sydney/Projects/2022_SELF_STUDY/kaggle/Yolov3/Yolov3_object_detection.ipynb#ch0000046?line=16'>17</a>\u001b[0m assign_ops \u001b[39m=\u001b[39m load_weights(model_vars, \u001b[39m\"\u001b[39m\u001b[39m../../Keras_YOLO/darknet/custom/darknet53.weights\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;32m/home/sydney/Projects/2022_SELF_STUDY/kaggle/Yolov3/Yolov3_object_detection.ipynb Cell 28'\u001b[0m in \u001b[0;36mYolo_v3.__call__\u001b[0;34m(self, inputs, training)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/sydney/Projects/2022_SELF_STUDY/kaggle/Yolov3/Yolov3_object_detection.ipynb#ch0000036?line=17'>18</a>\u001b[0m       inputs \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mtranspose(inputs, [\u001b[39m0\u001b[39m, \u001b[39m3\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m])\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/sydney/Projects/2022_SELF_STUDY/kaggle/Yolov3/Yolov3_object_detection.ipynb#ch0000036?line=19'>20</a>\u001b[0m inputs \u001b[39m=\u001b[39m inputs \u001b[39m/\u001b[39m \u001b[39m255\u001b[39m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/sydney/Projects/2022_SELF_STUDY/kaggle/Yolov3/Yolov3_object_detection.ipynb#ch0000036?line=21'>22</a>\u001b[0m route1, route2, inputs \u001b[39m=\u001b[39m darknet53(inputs, training\u001b[39m=\u001b[39;49mtraining, data_format\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdata_format)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/sydney/Projects/2022_SELF_STUDY/kaggle/Yolov3/Yolov3_object_detection.ipynb#ch0000036?line=23'>24</a>\u001b[0m route, inputs \u001b[39m=\u001b[39m yolo_convolution_block(inputs, filters\u001b[39m=\u001b[39m\u001b[39m512\u001b[39m, training\u001b[39m=\u001b[39mtraining, data_format\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata_format)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/sydney/Projects/2022_SELF_STUDY/kaggle/Yolov3/Yolov3_object_detection.ipynb#ch0000036?line=24'>25</a>\u001b[0m detect1 \u001b[39m=\u001b[39m yolo_layer(inputs, n_classes\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_classes, anchors\u001b[39m=\u001b[39m_ANCHORS[\u001b[39m6\u001b[39m:\u001b[39m9\u001b[39m], img_size\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel_size, data_format\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata_format)\n",
      "\u001b[1;32m/home/sydney/Projects/2022_SELF_STUDY/kaggle/Yolov3/Yolov3_object_detection.ipynb Cell 17'\u001b[0m in \u001b[0;36mdarknet53\u001b[0;34m(inputs, training, data_format)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/sydney/Projects/2022_SELF_STUDY/kaggle/Yolov3/Yolov3_object_detection.ipynb#ch0000018?line=0'>1</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdarknet53\u001b[39m(inputs, training, data_format):\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/sydney/Projects/2022_SELF_STUDY/kaggle/Yolov3/Yolov3_object_detection.ipynb#ch0000018?line=1'>2</a>\u001b[0m       inputs \u001b[39m=\u001b[39m conv2d_fixed_padding(inputs, filters\u001b[39m=\u001b[39;49m\u001b[39m32\u001b[39;49m, kernel_size\u001b[39m=\u001b[39;49m\u001b[39m3\u001b[39;49m, data_format\u001b[39m=\u001b[39;49mdata_format)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/sydney/Projects/2022_SELF_STUDY/kaggle/Yolov3/Yolov3_object_detection.ipynb#ch0000018?line=2'>3</a>\u001b[0m       inputs \u001b[39m=\u001b[39m batch_norm(inputs, training\u001b[39m=\u001b[39mtraining, data_format\u001b[39m=\u001b[39mdata_format)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/sydney/Projects/2022_SELF_STUDY/kaggle/Yolov3/Yolov3_object_detection.ipynb#ch0000018?line=3'>4</a>\u001b[0m       inputs \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mleaky_relu(inputs, alpha\u001b[39m=\u001b[39m_LEAKY_RELU)\n",
      "\u001b[1;32m/home/sydney/Projects/2022_SELF_STUDY/kaggle/Yolov3/Yolov3_object_detection.ipynb Cell 14'\u001b[0m in \u001b[0;36mconv2d_fixed_padding\u001b[0;34m(inputs, filters, kernel_size, data_format, strides)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/sydney/Projects/2022_SELF_STUDY/kaggle/Yolov3/Yolov3_object_detection.ipynb#ch0000007?line=20'>21</a>\u001b[0m \u001b[39mif\u001b[39;00m strides \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/sydney/Projects/2022_SELF_STUDY/kaggle/Yolov3/Yolov3_object_detection.ipynb#ch0000007?line=21'>22</a>\u001b[0m       inputs \u001b[39m=\u001b[39m fixed_padding(inputs, kernel_size, data_format)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/sydney/Projects/2022_SELF_STUDY/kaggle/Yolov3/Yolov3_object_detection.ipynb#ch0000007?line=23'>24</a>\u001b[0m \u001b[39mreturn\u001b[39;00m tf\u001b[39m.\u001b[39;49mlayers\u001b[39m.\u001b[39;49mconv2d(\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/sydney/Projects/2022_SELF_STUDY/kaggle/Yolov3/Yolov3_object_detection.ipynb#ch0000007?line=24'>25</a>\u001b[0m       inputs\u001b[39m=\u001b[39;49minputs, filters\u001b[39m=\u001b[39;49mfilters, kernel_size\u001b[39m=\u001b[39;49mkernel_size,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/sydney/Projects/2022_SELF_STUDY/kaggle/Yolov3/Yolov3_object_detection.ipynb#ch0000007?line=25'>26</a>\u001b[0m       strides\u001b[39m=\u001b[39;49mstrides, padding\u001b[39m=\u001b[39;49m(\u001b[39m\"\u001b[39;49m\u001b[39mSAME\u001b[39;49m\u001b[39m\"\u001b[39;49m \u001b[39mif\u001b[39;49;00m strides \u001b[39m==\u001b[39;49m \u001b[39m1\u001b[39;49m \u001b[39melse\u001b[39;49;00m \u001b[39m\"\u001b[39;49m\u001b[39mVALID\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/sydney/Projects/2022_SELF_STUDY/kaggle/Yolov3/Yolov3_object_detection.ipynb#ch0000007?line=26'>27</a>\u001b[0m       use_bias\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, data_format\u001b[39m=\u001b[39;49mdata_format)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/keras/legacy_tf_layers/convolutional.py:563\u001b[0m, in \u001b[0;36mconv2d\u001b[0;34m(inputs, filters, kernel_size, strides, padding, data_format, dilation_rate, activation, use_bias, kernel_initializer, bias_initializer, kernel_regularizer, bias_regularizer, activity_regularizer, kernel_constraint, bias_constraint, trainable, name, reuse)\u001b[0m\n\u001b[1;32m    <a href='file:///home/sydney/.local/lib/python3.8/site-packages/keras/legacy_tf_layers/convolutional.py?line=537'>538</a>\u001b[0m warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    <a href='file:///home/sydney/.local/lib/python3.8/site-packages/keras/legacy_tf_layers/convolutional.py?line=538'>539</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39m`tf.layers.conv2d` is deprecated and \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    <a href='file:///home/sydney/.local/lib/python3.8/site-packages/keras/legacy_tf_layers/convolutional.py?line=539'>540</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mwill be removed in a future version. \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    <a href='file:///home/sydney/.local/lib/python3.8/site-packages/keras/legacy_tf_layers/convolutional.py?line=540'>541</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mPlease Use `tf.keras.layers.Conv2D` instead.\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m    <a href='file:///home/sydney/.local/lib/python3.8/site-packages/keras/legacy_tf_layers/convolutional.py?line=541'>542</a>\u001b[0m     stacklevel\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[1;32m    <a href='file:///home/sydney/.local/lib/python3.8/site-packages/keras/legacy_tf_layers/convolutional.py?line=542'>543</a>\u001b[0m layer \u001b[39m=\u001b[39m Conv2D(\n\u001b[1;32m    <a href='file:///home/sydney/.local/lib/python3.8/site-packages/keras/legacy_tf_layers/convolutional.py?line=543'>544</a>\u001b[0m     filters\u001b[39m=\u001b[39mfilters,\n\u001b[1;32m    <a href='file:///home/sydney/.local/lib/python3.8/site-packages/keras/legacy_tf_layers/convolutional.py?line=544'>545</a>\u001b[0m     kernel_size\u001b[39m=\u001b[39mkernel_size,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///home/sydney/.local/lib/python3.8/site-packages/keras/legacy_tf_layers/convolutional.py?line=560'>561</a>\u001b[0m     _reuse\u001b[39m=\u001b[39mreuse,\n\u001b[1;32m    <a href='file:///home/sydney/.local/lib/python3.8/site-packages/keras/legacy_tf_layers/convolutional.py?line=561'>562</a>\u001b[0m     _scope\u001b[39m=\u001b[39mname)\n\u001b[0;32m--> <a href='file:///home/sydney/.local/lib/python3.8/site-packages/keras/legacy_tf_layers/convolutional.py?line=562'>563</a>\u001b[0m \u001b[39mreturn\u001b[39;00m layer\u001b[39m.\u001b[39;49mapply(inputs)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/keras/engine/base_layer_v1.py:1681\u001b[0m, in \u001b[0;36mLayer.apply\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///home/sydney/.local/lib/python3.8/site-packages/keras/engine/base_layer_v1.py?line=1663'>1664</a>\u001b[0m \u001b[39m\"\"\"Deprecated, do NOT use!\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/sydney/.local/lib/python3.8/site-packages/keras/engine/base_layer_v1.py?line=1664'>1665</a>\u001b[0m \n\u001b[1;32m   <a href='file:///home/sydney/.local/lib/python3.8/site-packages/keras/engine/base_layer_v1.py?line=1665'>1666</a>\u001b[0m \u001b[39mThis is an alias of `self.__call__`.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   <a href='file:///home/sydney/.local/lib/python3.8/site-packages/keras/engine/base_layer_v1.py?line=1673'>1674</a>\u001b[0m \u001b[39m  Output tensor(s).\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/sydney/.local/lib/python3.8/site-packages/keras/engine/base_layer_v1.py?line=1674'>1675</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/sydney/.local/lib/python3.8/site-packages/keras/engine/base_layer_v1.py?line=1675'>1676</a>\u001b[0m warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m   <a href='file:///home/sydney/.local/lib/python3.8/site-packages/keras/engine/base_layer_v1.py?line=1676'>1677</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39m`layer.apply` is deprecated and \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m   <a href='file:///home/sydney/.local/lib/python3.8/site-packages/keras/engine/base_layer_v1.py?line=1677'>1678</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mwill be removed in a future version. \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m   <a href='file:///home/sydney/.local/lib/python3.8/site-packages/keras/engine/base_layer_v1.py?line=1678'>1679</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mPlease use `layer.__call__` method instead.\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m   <a href='file:///home/sydney/.local/lib/python3.8/site-packages/keras/engine/base_layer_v1.py?line=1679'>1680</a>\u001b[0m     stacklevel\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[0;32m-> <a href='file:///home/sydney/.local/lib/python3.8/site-packages/keras/engine/base_layer_v1.py?line=1680'>1681</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(inputs, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/keras/legacy_tf_layers/base.py:569\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///home/sydney/.local/lib/python3.8/site-packages/keras/legacy_tf_layers/base.py?line=565'>566</a>\u001b[0m     kwargs[\u001b[39m'\u001b[39m\u001b[39mscope\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m scope\n\u001b[1;32m    <a href='file:///home/sydney/.local/lib/python3.8/site-packages/keras/legacy_tf_layers/base.py?line=567'>568</a>\u001b[0m   \u001b[39m# Actually call layer\u001b[39;00m\n\u001b[0;32m--> <a href='file:///home/sydney/.local/lib/python3.8/site-packages/keras/legacy_tf_layers/base.py?line=568'>569</a>\u001b[0m   outputs \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m(Layer, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(inputs, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    <a href='file:///home/sydney/.local/lib/python3.8/site-packages/keras/legacy_tf_layers/base.py?line=570'>571</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m tf\u001b[39m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m    <a href='file:///home/sydney/.local/lib/python3.8/site-packages/keras/legacy_tf_layers/base.py?line=571'>572</a>\u001b[0m   \u001b[39m# Update global default collections.\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/sydney/.local/lib/python3.8/site-packages/keras/legacy_tf_layers/base.py?line=572'>573</a>\u001b[0m   _add_elements_to_collection(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mupdates, tf\u001b[39m.\u001b[39mcompat\u001b[39m.\u001b[39mv1\u001b[39m.\u001b[39mGraphKeys\u001b[39m.\u001b[39mUPDATE_OPS)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/keras/engine/base_layer_v1.py:745\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///home/sydney/.local/lib/python3.8/site-packages/keras/engine/base_layer_v1.py?line=740'>741</a>\u001b[0m graph \u001b[39m=\u001b[39m backend\u001b[39m.\u001b[39mget_graph()\n\u001b[1;32m    <a href='file:///home/sydney/.local/lib/python3.8/site-packages/keras/engine/base_layer_v1.py?line=741'>742</a>\u001b[0m \u001b[39mwith\u001b[39;00m graph\u001b[39m.\u001b[39mas_default(), backend\u001b[39m.\u001b[39mname_scope(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_name_scope()):  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/sydney/.local/lib/python3.8/site-packages/keras/engine/base_layer_v1.py?line=742'>743</a>\u001b[0m   \u001b[39m# Build layer if applicable (if the `build` method has been\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/sydney/.local/lib/python3.8/site-packages/keras/engine/base_layer_v1.py?line=743'>744</a>\u001b[0m   \u001b[39m# overridden).\u001b[39;00m\n\u001b[0;32m--> <a href='file:///home/sydney/.local/lib/python3.8/site-packages/keras/engine/base_layer_v1.py?line=744'>745</a>\u001b[0m   \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_maybe_build(inputs)\n\u001b[1;32m    <a href='file:///home/sydney/.local/lib/python3.8/site-packages/keras/engine/base_layer_v1.py?line=745'>746</a>\u001b[0m   cast_inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_cast_inputs(inputs)\n\u001b[1;32m    <a href='file:///home/sydney/.local/lib/python3.8/site-packages/keras/engine/base_layer_v1.py?line=747'>748</a>\u001b[0m   \u001b[39m# Wrapping `call` function in autograph to allow for dynamic control\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/sydney/.local/lib/python3.8/site-packages/keras/engine/base_layer_v1.py?line=748'>749</a>\u001b[0m   \u001b[39m# flow and control dependencies in call. We are limiting this to\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/sydney/.local/lib/python3.8/site-packages/keras/engine/base_layer_v1.py?line=749'>750</a>\u001b[0m   \u001b[39m# subclassed layers as autograph is strictly needed only for\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/sydney/.local/lib/python3.8/site-packages/keras/engine/base_layer_v1.py?line=750'>751</a>\u001b[0m   \u001b[39m# subclassed layers and models.\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/sydney/.local/lib/python3.8/site-packages/keras/engine/base_layer_v1.py?line=751'>752</a>\u001b[0m   \u001b[39m# tf_convert will respect the value of autograph setting in the\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/sydney/.local/lib/python3.8/site-packages/keras/engine/base_layer_v1.py?line=752'>753</a>\u001b[0m   \u001b[39m# enclosing tf.function, if any.\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/keras/engine/base_layer_v1.py:2072\u001b[0m, in \u001b[0;36mLayer._maybe_build\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   <a href='file:///home/sydney/.local/lib/python3.8/site-packages/keras/engine/base_layer_v1.py?line=2066'>2067</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuild, \u001b[39m'\u001b[39m\u001b[39m_is_default\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m   <a href='file:///home/sydney/.local/lib/python3.8/site-packages/keras/engine/base_layer_v1.py?line=2067'>2068</a>\u001b[0m   \u001b[39m# Any setup work performed only once should happen in an `init_scope`\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/sydney/.local/lib/python3.8/site-packages/keras/engine/base_layer_v1.py?line=2068'>2069</a>\u001b[0m   \u001b[39m# to avoid creating symbolic Tensors that will later pollute any eager\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/sydney/.local/lib/python3.8/site-packages/keras/engine/base_layer_v1.py?line=2069'>2070</a>\u001b[0m   \u001b[39m# operations.\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/sydney/.local/lib/python3.8/site-packages/keras/engine/base_layer_v1.py?line=2070'>2071</a>\u001b[0m   \u001b[39mwith\u001b[39;00m tf_utils\u001b[39m.\u001b[39mmaybe_init_scope(\u001b[39mself\u001b[39m):\n\u001b[0;32m-> <a href='file:///home/sydney/.local/lib/python3.8/site-packages/keras/engine/base_layer_v1.py?line=2071'>2072</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbuild(input_shapes)\n\u001b[1;32m   <a href='file:///home/sydney/.local/lib/python3.8/site-packages/keras/engine/base_layer_v1.py?line=2072'>2073</a>\u001b[0m \u001b[39m# We must set also ensure that the layer is marked as built, and the build\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/sydney/.local/lib/python3.8/site-packages/keras/engine/base_layer_v1.py?line=2073'>2074</a>\u001b[0m \u001b[39m# shape is stored since user defined build functions may not be calling\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/sydney/.local/lib/python3.8/site-packages/keras/engine/base_layer_v1.py?line=2074'>2075</a>\u001b[0m \u001b[39m# `super.build()`\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/sydney/.local/lib/python3.8/site-packages/keras/engine/base_layer_v1.py?line=2075'>2076</a>\u001b[0m Layer\u001b[39m.\u001b[39mbuild(\u001b[39mself\u001b[39m, input_shapes)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/keras/layers/convolutional.py:199\u001b[0m, in \u001b[0;36mConv.build\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m    <a href='file:///home/sydney/.local/lib/python3.8/site-packages/keras/layers/convolutional.py?line=193'>194</a>\u001b[0m kernel_shape \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkernel_size \u001b[39m+\u001b[39m (input_channel \u001b[39m/\u001b[39m\u001b[39m/\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups,\n\u001b[1;32m    <a href='file:///home/sydney/.local/lib/python3.8/site-packages/keras/layers/convolutional.py?line=194'>195</a>\u001b[0m                                    \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfilters)\n\u001b[1;32m    <a href='file:///home/sydney/.local/lib/python3.8/site-packages/keras/layers/convolutional.py?line=196'>197</a>\u001b[0m output_shape \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcompute_output_shape(input_shape)\n\u001b[0;32m--> <a href='file:///home/sydney/.local/lib/python3.8/site-packages/keras/layers/convolutional.py?line=198'>199</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkernel \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49madd_weight(\n\u001b[1;32m    <a href='file:///home/sydney/.local/lib/python3.8/site-packages/keras/layers/convolutional.py?line=199'>200</a>\u001b[0m     name\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mkernel\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m    <a href='file:///home/sydney/.local/lib/python3.8/site-packages/keras/layers/convolutional.py?line=200'>201</a>\u001b[0m     shape\u001b[39m=\u001b[39;49mkernel_shape,\n\u001b[1;32m    <a href='file:///home/sydney/.local/lib/python3.8/site-packages/keras/layers/convolutional.py?line=201'>202</a>\u001b[0m     initializer\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mkernel_initializer,\n\u001b[1;32m    <a href='file:///home/sydney/.local/lib/python3.8/site-packages/keras/layers/convolutional.py?line=202'>203</a>\u001b[0m     regularizer\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mkernel_regularizer,\n\u001b[1;32m    <a href='file:///home/sydney/.local/lib/python3.8/site-packages/keras/layers/convolutional.py?line=203'>204</a>\u001b[0m     constraint\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mkernel_constraint,\n\u001b[1;32m    <a href='file:///home/sydney/.local/lib/python3.8/site-packages/keras/layers/convolutional.py?line=204'>205</a>\u001b[0m     trainable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    <a href='file:///home/sydney/.local/lib/python3.8/site-packages/keras/layers/convolutional.py?line=205'>206</a>\u001b[0m     dtype\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdtype)\n\u001b[1;32m    <a href='file:///home/sydney/.local/lib/python3.8/site-packages/keras/layers/convolutional.py?line=206'>207</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39muse_bias:\n\u001b[1;32m    <a href='file:///home/sydney/.local/lib/python3.8/site-packages/keras/layers/convolutional.py?line=207'>208</a>\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbias \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39madd_weight(\n\u001b[1;32m    <a href='file:///home/sydney/.local/lib/python3.8/site-packages/keras/layers/convolutional.py?line=208'>209</a>\u001b[0m       name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mbias\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m    <a href='file:///home/sydney/.local/lib/python3.8/site-packages/keras/layers/convolutional.py?line=209'>210</a>\u001b[0m       shape\u001b[39m=\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfilters,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///home/sydney/.local/lib/python3.8/site-packages/keras/layers/convolutional.py?line=213'>214</a>\u001b[0m       trainable\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m    <a href='file:///home/sydney/.local/lib/python3.8/site-packages/keras/layers/convolutional.py?line=214'>215</a>\u001b[0m       dtype\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdtype)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/keras/legacy_tf_layers/base.py:456\u001b[0m, in \u001b[0;36mLayer.add_weight\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, trainable, constraint, use_resource, synchronization, aggregation, partitioner, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///home/sydney/.local/lib/python3.8/site-packages/keras/legacy_tf_layers/base.py?line=453'>454</a>\u001b[0m \u001b[39mif\u001b[39;00m initializer \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    <a href='file:///home/sydney/.local/lib/python3.8/site-packages/keras/legacy_tf_layers/base.py?line=454'>455</a>\u001b[0m   initializer \u001b[39m=\u001b[39m scope\u001b[39m.\u001b[39minitializer\n\u001b[0;32m--> <a href='file:///home/sydney/.local/lib/python3.8/site-packages/keras/legacy_tf_layers/base.py?line=455'>456</a>\u001b[0m variable \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m(Layer, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49madd_weight(\n\u001b[1;32m    <a href='file:///home/sydney/.local/lib/python3.8/site-packages/keras/legacy_tf_layers/base.py?line=456'>457</a>\u001b[0m     name,\n\u001b[1;32m    <a href='file:///home/sydney/.local/lib/python3.8/site-packages/keras/legacy_tf_layers/base.py?line=457'>458</a>\u001b[0m     shape,\n\u001b[1;32m    <a href='file:///home/sydney/.local/lib/python3.8/site-packages/keras/legacy_tf_layers/base.py?line=458'>459</a>\u001b[0m     dtype\u001b[39m=\u001b[39;49mtf\u001b[39m.\u001b[39;49mas_dtype(dtype),\n\u001b[1;32m    <a href='file:///home/sydney/.local/lib/python3.8/site-packages/keras/legacy_tf_layers/base.py?line=459'>460</a>\u001b[0m     initializer\u001b[39m=\u001b[39;49minitializer,\n\u001b[1;32m    <a href='file:///home/sydney/.local/lib/python3.8/site-packages/keras/legacy_tf_layers/base.py?line=460'>461</a>\u001b[0m     trainable\u001b[39m=\u001b[39;49mtrainable \u001b[39mand\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrainable,\n\u001b[1;32m    <a href='file:///home/sydney/.local/lib/python3.8/site-packages/keras/legacy_tf_layers/base.py?line=461'>462</a>\u001b[0m     constraint\u001b[39m=\u001b[39;49mconstraint,\n\u001b[1;32m    <a href='file:///home/sydney/.local/lib/python3.8/site-packages/keras/legacy_tf_layers/base.py?line=462'>463</a>\u001b[0m     partitioner\u001b[39m=\u001b[39;49mpartitioner,\n\u001b[1;32m    <a href='file:///home/sydney/.local/lib/python3.8/site-packages/keras/legacy_tf_layers/base.py?line=463'>464</a>\u001b[0m     use_resource\u001b[39m=\u001b[39;49muse_resource,\n\u001b[1;32m    <a href='file:///home/sydney/.local/lib/python3.8/site-packages/keras/legacy_tf_layers/base.py?line=464'>465</a>\u001b[0m     synchronization\u001b[39m=\u001b[39;49msynchronization,\n\u001b[1;32m    <a href='file:///home/sydney/.local/lib/python3.8/site-packages/keras/legacy_tf_layers/base.py?line=465'>466</a>\u001b[0m     aggregation\u001b[39m=\u001b[39;49maggregation,\n\u001b[1;32m    <a href='file:///home/sydney/.local/lib/python3.8/site-packages/keras/legacy_tf_layers/base.py?line=466'>467</a>\u001b[0m     getter\u001b[39m=\u001b[39;49mtf\u001b[39m.\u001b[39;49mcompat\u001b[39m.\u001b[39;49mv1\u001b[39m.\u001b[39;49mget_variable,\n\u001b[1;32m    <a href='file:///home/sydney/.local/lib/python3.8/site-packages/keras/legacy_tf_layers/base.py?line=467'>468</a>\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    <a href='file:///home/sydney/.local/lib/python3.8/site-packages/keras/legacy_tf_layers/base.py?line=469'>470</a>\u001b[0m \u001b[39mif\u001b[39;00m regularizer:\n\u001b[1;32m    <a href='file:///home/sydney/.local/lib/python3.8/site-packages/keras/legacy_tf_layers/base.py?line=470'>471</a>\u001b[0m   \u001b[39mif\u001b[39;00m (tf\u001b[39m.\u001b[39mcompat\u001b[39m.\u001b[39mv1\u001b[39m.\u001b[39mexecuting_eagerly_outside_functions()\n\u001b[1;32m    <a href='file:///home/sydney/.local/lib/python3.8/site-packages/keras/legacy_tf_layers/base.py?line=471'>472</a>\u001b[0m       \u001b[39mor\u001b[39;00m _should_add_regularizer(variable, existing_variables)):\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/keras/engine/base_layer_v1.py:423\u001b[0m, in \u001b[0;36mLayer.add_weight\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, trainable, constraint, partitioner, use_resource, synchronization, aggregation, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///home/sydney/.local/lib/python3.8/site-packages/keras/engine/base_layer_v1.py?line=417'>418</a>\u001b[0m     tf_logging\u001b[39m.\u001b[39mwarning(\n\u001b[1;32m    <a href='file:///home/sydney/.local/lib/python3.8/site-packages/keras/engine/base_layer_v1.py?line=418'>419</a>\u001b[0m         \u001b[39m'\u001b[39m\u001b[39m`caching_device` does not work with mixed precision API. Ignoring \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    <a href='file:///home/sydney/.local/lib/python3.8/site-packages/keras/engine/base_layer_v1.py?line=419'>420</a>\u001b[0m         \u001b[39m'\u001b[39m\u001b[39muser specified `caching_device`.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    <a href='file:///home/sydney/.local/lib/python3.8/site-packages/keras/engine/base_layer_v1.py?line=420'>421</a>\u001b[0m     caching_device \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> <a href='file:///home/sydney/.local/lib/python3.8/site-packages/keras/engine/base_layer_v1.py?line=422'>423</a>\u001b[0m variable \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_add_variable_with_custom_getter(\n\u001b[1;32m    <a href='file:///home/sydney/.local/lib/python3.8/site-packages/keras/engine/base_layer_v1.py?line=423'>424</a>\u001b[0m     name\u001b[39m=\u001b[39;49mname,\n\u001b[1;32m    <a href='file:///home/sydney/.local/lib/python3.8/site-packages/keras/engine/base_layer_v1.py?line=424'>425</a>\u001b[0m     shape\u001b[39m=\u001b[39;49mshape,\n\u001b[1;32m    <a href='file:///home/sydney/.local/lib/python3.8/site-packages/keras/engine/base_layer_v1.py?line=425'>426</a>\u001b[0m     \u001b[39m# TODO(allenl): a `make_variable` equivalent should be added as a\u001b[39;49;00m\n\u001b[1;32m    <a href='file:///home/sydney/.local/lib/python3.8/site-packages/keras/engine/base_layer_v1.py?line=426'>427</a>\u001b[0m     \u001b[39m# `Trackable` method.\u001b[39;49;00m\n\u001b[1;32m    <a href='file:///home/sydney/.local/lib/python3.8/site-packages/keras/engine/base_layer_v1.py?line=427'>428</a>\u001b[0m     getter\u001b[39m=\u001b[39;49mgetter,\n\u001b[1;32m    <a href='file:///home/sydney/.local/lib/python3.8/site-packages/keras/engine/base_layer_v1.py?line=428'>429</a>\u001b[0m     \u001b[39m# Manage errors in Layer rather than Trackable.\u001b[39;49;00m\n\u001b[1;32m    <a href='file:///home/sydney/.local/lib/python3.8/site-packages/keras/engine/base_layer_v1.py?line=429'>430</a>\u001b[0m     overwrite\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    <a href='file:///home/sydney/.local/lib/python3.8/site-packages/keras/engine/base_layer_v1.py?line=430'>431</a>\u001b[0m     initializer\u001b[39m=\u001b[39;49minitializer,\n\u001b[1;32m    <a href='file:///home/sydney/.local/lib/python3.8/site-packages/keras/engine/base_layer_v1.py?line=431'>432</a>\u001b[0m     dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[1;32m    <a href='file:///home/sydney/.local/lib/python3.8/site-packages/keras/engine/base_layer_v1.py?line=432'>433</a>\u001b[0m     constraint\u001b[39m=\u001b[39;49mconstraint,\n\u001b[1;32m    <a href='file:///home/sydney/.local/lib/python3.8/site-packages/keras/engine/base_layer_v1.py?line=433'>434</a>\u001b[0m     trainable\u001b[39m=\u001b[39;49mtrainable,\n\u001b[1;32m    <a href='file:///home/sydney/.local/lib/python3.8/site-packages/keras/engine/base_layer_v1.py?line=434'>435</a>\u001b[0m     partitioner\u001b[39m=\u001b[39;49mpartitioner,\n\u001b[1;32m    <a href='file:///home/sydney/.local/lib/python3.8/site-packages/keras/engine/base_layer_v1.py?line=435'>436</a>\u001b[0m     use_resource\u001b[39m=\u001b[39;49muse_resource,\n\u001b[1;32m    <a href='file:///home/sydney/.local/lib/python3.8/site-packages/keras/engine/base_layer_v1.py?line=436'>437</a>\u001b[0m     collections\u001b[39m=\u001b[39;49mcollections_arg,\n\u001b[1;32m    <a href='file:///home/sydney/.local/lib/python3.8/site-packages/keras/engine/base_layer_v1.py?line=437'>438</a>\u001b[0m     synchronization\u001b[39m=\u001b[39;49msynchronization,\n\u001b[1;32m    <a href='file:///home/sydney/.local/lib/python3.8/site-packages/keras/engine/base_layer_v1.py?line=438'>439</a>\u001b[0m     aggregation\u001b[39m=\u001b[39;49maggregation,\n\u001b[1;32m    <a href='file:///home/sydney/.local/lib/python3.8/site-packages/keras/engine/base_layer_v1.py?line=439'>440</a>\u001b[0m     caching_device\u001b[39m=\u001b[39;49mcaching_device)\n\u001b[1;32m    <a href='file:///home/sydney/.local/lib/python3.8/site-packages/keras/engine/base_layer_v1.py?line=440'>441</a>\u001b[0m \u001b[39mif\u001b[39;00m regularizer \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    <a href='file:///home/sydney/.local/lib/python3.8/site-packages/keras/engine/base_layer_v1.py?line=441'>442</a>\u001b[0m   \u001b[39m# TODO(fchollet): in the future, this should be handled at the\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/sydney/.local/lib/python3.8/site-packages/keras/engine/base_layer_v1.py?line=442'>443</a>\u001b[0m   \u001b[39m# level of variable creation, and weight regularization losses\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/sydney/.local/lib/python3.8/site-packages/keras/engine/base_layer_v1.py?line=443'>444</a>\u001b[0m   \u001b[39m# should be variable attributes.\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/sydney/.local/lib/python3.8/site-packages/keras/engine/base_layer_v1.py?line=444'>445</a>\u001b[0m   name_in_scope \u001b[39m=\u001b[39m variable\u001b[39m.\u001b[39mname[:variable\u001b[39m.\u001b[39mname\u001b[39m.\u001b[39mfind(\u001b[39m'\u001b[39m\u001b[39m:\u001b[39m\u001b[39m'\u001b[39m)]\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/training/tracking/base.py:816\u001b[0m, in \u001b[0;36mTrackable._add_variable_with_custom_getter\u001b[0;34m(self, name, shape, dtype, initializer, getter, overwrite, **kwargs_for_getter)\u001b[0m\n\u001b[1;32m    <a href='file:///home/sydney/.local/lib/python3.8/site-packages/tensorflow/python/training/tracking/base.py?line=805'>806</a>\u001b[0m   \u001b[39mif\u001b[39;00m (checkpoint_initializer \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/sydney/.local/lib/python3.8/site-packages/tensorflow/python/training/tracking/base.py?line=806'>807</a>\u001b[0m       \u001b[39mnot\u001b[39;00m (\u001b[39misinstance\u001b[39m(initializer, CheckpointInitialValueCallable) \u001b[39mand\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/sydney/.local/lib/python3.8/site-packages/tensorflow/python/training/tracking/base.py?line=807'>808</a>\u001b[0m            (initializer\u001b[39m.\u001b[39mrestore_uid \u001b[39m>\u001b[39m checkpoint_initializer\u001b[39m.\u001b[39mrestore_uid))):\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///home/sydney/.local/lib/python3.8/site-packages/tensorflow/python/training/tracking/base.py?line=812'>813</a>\u001b[0m     \u001b[39m# then we'll catch that when we call _track_trackable. So this is\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/sydney/.local/lib/python3.8/site-packages/tensorflow/python/training/tracking/base.py?line=813'>814</a>\u001b[0m     \u001b[39m# \"best effort\" to set the initializer with the highest restore UID.\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/sydney/.local/lib/python3.8/site-packages/tensorflow/python/training/tracking/base.py?line=814'>815</a>\u001b[0m     initializer \u001b[39m=\u001b[39m checkpoint_initializer\n\u001b[0;32m--> <a href='file:///home/sydney/.local/lib/python3.8/site-packages/tensorflow/python/training/tracking/base.py?line=815'>816</a>\u001b[0m new_variable \u001b[39m=\u001b[39m getter(\n\u001b[1;32m    <a href='file:///home/sydney/.local/lib/python3.8/site-packages/tensorflow/python/training/tracking/base.py?line=816'>817</a>\u001b[0m     name\u001b[39m=\u001b[39;49mname,\n\u001b[1;32m    <a href='file:///home/sydney/.local/lib/python3.8/site-packages/tensorflow/python/training/tracking/base.py?line=817'>818</a>\u001b[0m     shape\u001b[39m=\u001b[39;49mshape,\n\u001b[1;32m    <a href='file:///home/sydney/.local/lib/python3.8/site-packages/tensorflow/python/training/tracking/base.py?line=818'>819</a>\u001b[0m     dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[1;32m    <a href='file:///home/sydney/.local/lib/python3.8/site-packages/tensorflow/python/training/tracking/base.py?line=819'>820</a>\u001b[0m     initializer\u001b[39m=\u001b[39;49minitializer,\n\u001b[1;32m    <a href='file:///home/sydney/.local/lib/python3.8/site-packages/tensorflow/python/training/tracking/base.py?line=820'>821</a>\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs_for_getter)\n\u001b[1;32m    <a href='file:///home/sydney/.local/lib/python3.8/site-packages/tensorflow/python/training/tracking/base.py?line=822'>823</a>\u001b[0m \u001b[39m# If we set an initializer and the variable processed it, tracking will not\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/sydney/.local/lib/python3.8/site-packages/tensorflow/python/training/tracking/base.py?line=823'>824</a>\u001b[0m \u001b[39m# assign again. It will add this variable to our dependencies, and if there\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/sydney/.local/lib/python3.8/site-packages/tensorflow/python/training/tracking/base.py?line=824'>825</a>\u001b[0m \u001b[39m# is a non-trivial restoration queued, it will handle that. This also\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/sydney/.local/lib/python3.8/site-packages/tensorflow/python/training/tracking/base.py?line=825'>826</a>\u001b[0m \u001b[39m# handles slot variables.\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/sydney/.local/lib/python3.8/site-packages/tensorflow/python/training/tracking/base.py?line=826'>827</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m overwrite \u001b[39mor\u001b[39;00m \u001b[39misinstance\u001b[39m(new_variable, Trackable):\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/ops/variable_scope.py:1579\u001b[0m, in \u001b[0;36mget_variable\u001b[0;34m(name, shape, dtype, initializer, regularizer, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint, synchronization, aggregation)\u001b[0m\n\u001b[1;32m   <a href='file:///home/sydney/.local/lib/python3.8/site-packages/tensorflow/python/ops/variable_scope.py?line=1562'>1563</a>\u001b[0m \u001b[39m@tf_export\u001b[39m(v1\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mget_variable\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m   <a href='file:///home/sydney/.local/lib/python3.8/site-packages/tensorflow/python/ops/variable_scope.py?line=1563'>1564</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_variable\u001b[39m(name,\n\u001b[1;32m   <a href='file:///home/sydney/.local/lib/python3.8/site-packages/tensorflow/python/ops/variable_scope.py?line=1564'>1565</a>\u001b[0m                  shape\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   <a href='file:///home/sydney/.local/lib/python3.8/site-packages/tensorflow/python/ops/variable_scope.py?line=1576'>1577</a>\u001b[0m                  synchronization\u001b[39m=\u001b[39mVariableSynchronization\u001b[39m.\u001b[39mAUTO,\n\u001b[1;32m   <a href='file:///home/sydney/.local/lib/python3.8/site-packages/tensorflow/python/ops/variable_scope.py?line=1577'>1578</a>\u001b[0m                  aggregation\u001b[39m=\u001b[39mVariableAggregation\u001b[39m.\u001b[39mNONE):\n\u001b[0;32m-> <a href='file:///home/sydney/.local/lib/python3.8/site-packages/tensorflow/python/ops/variable_scope.py?line=1578'>1579</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m get_variable_scope()\u001b[39m.\u001b[39;49mget_variable(\n\u001b[1;32m   <a href='file:///home/sydney/.local/lib/python3.8/site-packages/tensorflow/python/ops/variable_scope.py?line=1579'>1580</a>\u001b[0m       _get_default_variable_store(),\n\u001b[1;32m   <a href='file:///home/sydney/.local/lib/python3.8/site-packages/tensorflow/python/ops/variable_scope.py?line=1580'>1581</a>\u001b[0m       name,\n\u001b[1;32m   <a href='file:///home/sydney/.local/lib/python3.8/site-packages/tensorflow/python/ops/variable_scope.py?line=1581'>1582</a>\u001b[0m       shape\u001b[39m=\u001b[39;49mshape,\n\u001b[1;32m   <a href='file:///home/sydney/.local/lib/python3.8/site-packages/tensorflow/python/ops/variable_scope.py?line=1582'>1583</a>\u001b[0m       dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[1;32m   <a href='file:///home/sydney/.local/lib/python3.8/site-packages/tensorflow/python/ops/variable_scope.py?line=1583'>1584</a>\u001b[0m       initializer\u001b[39m=\u001b[39;49minitializer,\n\u001b[1;32m   <a href='file:///home/sydney/.local/lib/python3.8/site-packages/tensorflow/python/ops/variable_scope.py?line=1584'>1585</a>\u001b[0m       regularizer\u001b[39m=\u001b[39;49mregularizer,\n\u001b[1;32m   <a href='file:///home/sydney/.local/lib/python3.8/site-packages/tensorflow/python/ops/variable_scope.py?line=1585'>1586</a>\u001b[0m       trainable\u001b[39m=\u001b[39;49mtrainable,\n\u001b[1;32m   <a href='file:///home/sydney/.local/lib/python3.8/site-packages/tensorflow/python/ops/variable_scope.py?line=1586'>1587</a>\u001b[0m       collections\u001b[39m=\u001b[39;49mcollections,\n\u001b[1;32m   <a href='file:///home/sydney/.local/lib/python3.8/site-packages/tensorflow/python/ops/variable_scope.py?line=1587'>1588</a>\u001b[0m       caching_device\u001b[39m=\u001b[39;49mcaching_device,\n\u001b[1;32m   <a href='file:///home/sydney/.local/lib/python3.8/site-packages/tensorflow/python/ops/variable_scope.py?line=1588'>1589</a>\u001b[0m       partitioner\u001b[39m=\u001b[39;49mpartitioner,\n\u001b[1;32m   <a href='file:///home/sydney/.local/lib/python3.8/site-packages/tensorflow/python/ops/variable_scope.py?line=1589'>1590</a>\u001b[0m       validate_shape\u001b[39m=\u001b[39;49mvalidate_shape,\n\u001b[1;32m   <a href='file:///home/sydney/.local/lib/python3.8/site-packages/tensorflow/python/ops/variable_scope.py?line=1590'>1591</a>\u001b[0m       use_resource\u001b[39m=\u001b[39;49muse_resource,\n\u001b[1;32m   <a href='file:///home/sydney/.local/lib/python3.8/site-packages/tensorflow/python/ops/variable_scope.py?line=1591'>1592</a>\u001b[0m       custom_getter\u001b[39m=\u001b[39;49mcustom_getter,\n\u001b[1;32m   <a href='file:///home/sydney/.local/lib/python3.8/site-packages/tensorflow/python/ops/variable_scope.py?line=1592'>1593</a>\u001b[0m       constraint\u001b[39m=\u001b[39;49mconstraint,\n\u001b[1;32m   <a href='file:///home/sydney/.local/lib/python3.8/site-packages/tensorflow/python/ops/variable_scope.py?line=1593'>1594</a>\u001b[0m       synchronization\u001b[39m=\u001b[39;49msynchronization,\n\u001b[1;32m   <a href='file:///home/sydney/.local/lib/python3.8/site-packages/tensorflow/python/ops/variable_scope.py?line=1594'>1595</a>\u001b[0m       aggregation\u001b[39m=\u001b[39;49maggregation)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/ops/variable_scope.py:1322\u001b[0m, in \u001b[0;36mVariableScope.get_variable\u001b[0;34m(self, var_store, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint, synchronization, aggregation)\u001b[0m\n\u001b[1;32m   <a href='file:///home/sydney/.local/lib/python3.8/site-packages/tensorflow/python/ops/variable_scope.py?line=1319'>1320</a>\u001b[0m \u001b[39mif\u001b[39;00m dtype \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   <a href='file:///home/sydney/.local/lib/python3.8/site-packages/tensorflow/python/ops/variable_scope.py?line=1320'>1321</a>\u001b[0m   dtype \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dtype\n\u001b[0;32m-> <a href='file:///home/sydney/.local/lib/python3.8/site-packages/tensorflow/python/ops/variable_scope.py?line=1321'>1322</a>\u001b[0m \u001b[39mreturn\u001b[39;00m var_store\u001b[39m.\u001b[39;49mget_variable(\n\u001b[1;32m   <a href='file:///home/sydney/.local/lib/python3.8/site-packages/tensorflow/python/ops/variable_scope.py?line=1322'>1323</a>\u001b[0m     full_name,\n\u001b[1;32m   <a href='file:///home/sydney/.local/lib/python3.8/site-packages/tensorflow/python/ops/variable_scope.py?line=1323'>1324</a>\u001b[0m     shape\u001b[39m=\u001b[39;49mshape,\n\u001b[1;32m   <a href='file:///home/sydney/.local/lib/python3.8/site-packages/tensorflow/python/ops/variable_scope.py?line=1324'>1325</a>\u001b[0m     dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[1;32m   <a href='file:///home/sydney/.local/lib/python3.8/site-packages/tensorflow/python/ops/variable_scope.py?line=1325'>1326</a>\u001b[0m     initializer\u001b[39m=\u001b[39;49minitializer,\n\u001b[1;32m   <a href='file:///home/sydney/.local/lib/python3.8/site-packages/tensorflow/python/ops/variable_scope.py?line=1326'>1327</a>\u001b[0m     regularizer\u001b[39m=\u001b[39;49mregularizer,\n\u001b[1;32m   <a href='file:///home/sydney/.local/lib/python3.8/site-packages/tensorflow/python/ops/variable_scope.py?line=1327'>1328</a>\u001b[0m     reuse\u001b[39m=\u001b[39;49mreuse,\n\u001b[1;32m   <a href='file:///home/sydney/.local/lib/python3.8/site-packages/tensorflow/python/ops/variable_scope.py?line=1328'>1329</a>\u001b[0m     trainable\u001b[39m=\u001b[39;49mtrainable,\n\u001b[1;32m   <a href='file:///home/sydney/.local/lib/python3.8/site-packages/tensorflow/python/ops/variable_scope.py?line=1329'>1330</a>\u001b[0m     collections\u001b[39m=\u001b[39;49mcollections,\n\u001b[1;32m   <a href='file:///home/sydney/.local/lib/python3.8/site-packages/tensorflow/python/ops/variable_scope.py?line=1330'>1331</a>\u001b[0m     caching_device\u001b[39m=\u001b[39;49mcaching_device,\n\u001b[1;32m   <a href='file:///home/sydney/.local/lib/python3.8/site-packages/tensorflow/python/ops/variable_scope.py?line=1331'>1332</a>\u001b[0m     partitioner\u001b[39m=\u001b[39;49mpartitioner,\n\u001b[1;32m   <a href='file:///home/sydney/.local/lib/python3.8/site-packages/tensorflow/python/ops/variable_scope.py?line=1332'>1333</a>\u001b[0m     validate_shape\u001b[39m=\u001b[39;49mvalidate_shape,\n\u001b[1;32m   <a href='file:///home/sydney/.local/lib/python3.8/site-packages/tensorflow/python/ops/variable_scope.py?line=1333'>1334</a>\u001b[0m     use_resource\u001b[39m=\u001b[39;49muse_resource,\n\u001b[1;32m   <a href='file:///home/sydney/.local/lib/python3.8/site-packages/tensorflow/python/ops/variable_scope.py?line=1334'>1335</a>\u001b[0m     custom_getter\u001b[39m=\u001b[39;49mcustom_getter,\n\u001b[1;32m   <a href='file:///home/sydney/.local/lib/python3.8/site-packages/tensorflow/python/ops/variable_scope.py?line=1335'>1336</a>\u001b[0m     constraint\u001b[39m=\u001b[39;49mconstraint,\n\u001b[1;32m   <a href='file:///home/sydney/.local/lib/python3.8/site-packages/tensorflow/python/ops/variable_scope.py?line=1336'>1337</a>\u001b[0m     synchronization\u001b[39m=\u001b[39;49msynchronization,\n\u001b[1;32m   <a href='file:///home/sydney/.local/lib/python3.8/site-packages/tensorflow/python/ops/variable_scope.py?line=1337'>1338</a>\u001b[0m     aggregation\u001b[39m=\u001b[39;49maggregation)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/ops/variable_scope.py:578\u001b[0m, in \u001b[0;36m_VariableStore.get_variable\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint, synchronization, aggregation)\u001b[0m\n\u001b[1;32m    <a href='file:///home/sydney/.local/lib/python3.8/site-packages/tensorflow/python/ops/variable_scope.py?line=575'>576</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m custom_getter(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcustom_getter_kwargs)\n\u001b[1;32m    <a href='file:///home/sydney/.local/lib/python3.8/site-packages/tensorflow/python/ops/variable_scope.py?line=576'>577</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///home/sydney/.local/lib/python3.8/site-packages/tensorflow/python/ops/variable_scope.py?line=577'>578</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m _true_getter(\n\u001b[1;32m    <a href='file:///home/sydney/.local/lib/python3.8/site-packages/tensorflow/python/ops/variable_scope.py?line=578'>579</a>\u001b[0m       name,\n\u001b[1;32m    <a href='file:///home/sydney/.local/lib/python3.8/site-packages/tensorflow/python/ops/variable_scope.py?line=579'>580</a>\u001b[0m       shape\u001b[39m=\u001b[39;49mshape,\n\u001b[1;32m    <a href='file:///home/sydney/.local/lib/python3.8/site-packages/tensorflow/python/ops/variable_scope.py?line=580'>581</a>\u001b[0m       dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[1;32m    <a href='file:///home/sydney/.local/lib/python3.8/site-packages/tensorflow/python/ops/variable_scope.py?line=581'>582</a>\u001b[0m       initializer\u001b[39m=\u001b[39;49minitializer,\n\u001b[1;32m    <a href='file:///home/sydney/.local/lib/python3.8/site-packages/tensorflow/python/ops/variable_scope.py?line=582'>583</a>\u001b[0m       regularizer\u001b[39m=\u001b[39;49mregularizer,\n\u001b[1;32m    <a href='file:///home/sydney/.local/lib/python3.8/site-packages/tensorflow/python/ops/variable_scope.py?line=583'>584</a>\u001b[0m       reuse\u001b[39m=\u001b[39;49mreuse,\n\u001b[1;32m    <a href='file:///home/sydney/.local/lib/python3.8/site-packages/tensorflow/python/ops/variable_scope.py?line=584'>585</a>\u001b[0m       trainable\u001b[39m=\u001b[39;49mtrainable,\n\u001b[1;32m    <a href='file:///home/sydney/.local/lib/python3.8/site-packages/tensorflow/python/ops/variable_scope.py?line=585'>586</a>\u001b[0m       collections\u001b[39m=\u001b[39;49mcollections,\n\u001b[1;32m    <a href='file:///home/sydney/.local/lib/python3.8/site-packages/tensorflow/python/ops/variable_scope.py?line=586'>587</a>\u001b[0m       caching_device\u001b[39m=\u001b[39;49mcaching_device,\n\u001b[1;32m    <a href='file:///home/sydney/.local/lib/python3.8/site-packages/tensorflow/python/ops/variable_scope.py?line=587'>588</a>\u001b[0m       partitioner\u001b[39m=\u001b[39;49mpartitioner,\n\u001b[1;32m    <a href='file:///home/sydney/.local/lib/python3.8/site-packages/tensorflow/python/ops/variable_scope.py?line=588'>589</a>\u001b[0m       validate_shape\u001b[39m=\u001b[39;49mvalidate_shape,\n\u001b[1;32m    <a href='file:///home/sydney/.local/lib/python3.8/site-packages/tensorflow/python/ops/variable_scope.py?line=589'>590</a>\u001b[0m       use_resource\u001b[39m=\u001b[39;49muse_resource,\n\u001b[1;32m    <a href='file:///home/sydney/.local/lib/python3.8/site-packages/tensorflow/python/ops/variable_scope.py?line=590'>591</a>\u001b[0m       constraint\u001b[39m=\u001b[39;49mconstraint,\n\u001b[1;32m    <a href='file:///home/sydney/.local/lib/python3.8/site-packages/tensorflow/python/ops/variable_scope.py?line=591'>592</a>\u001b[0m       synchronization\u001b[39m=\u001b[39;49msynchronization,\n\u001b[1;32m    <a href='file:///home/sydney/.local/lib/python3.8/site-packages/tensorflow/python/ops/variable_scope.py?line=592'>593</a>\u001b[0m       aggregation\u001b[39m=\u001b[39;49maggregation)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/ops/variable_scope.py:531\u001b[0m, in \u001b[0;36m_VariableStore.get_variable.<locals>._true_getter\u001b[0;34m(name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, constraint, synchronization, aggregation)\u001b[0m\n\u001b[1;32m    <a href='file:///home/sydney/.local/lib/python3.8/site-packages/tensorflow/python/ops/variable_scope.py?line=524'>525</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m/part_0\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m name \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_vars:\n\u001b[1;32m    <a href='file:///home/sydney/.local/lib/python3.8/site-packages/tensorflow/python/ops/variable_scope.py?line=525'>526</a>\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    <a href='file:///home/sydney/.local/lib/python3.8/site-packages/tensorflow/python/ops/variable_scope.py?line=526'>527</a>\u001b[0m       \u001b[39m\"\u001b[39m\u001b[39mNo partitioner was provided, but a partitioned version of the \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///home/sydney/.local/lib/python3.8/site-packages/tensorflow/python/ops/variable_scope.py?line=527'>528</a>\u001b[0m       \u001b[39m\"\u001b[39m\u001b[39mvariable was found: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m/part_0. Perhaps a variable of the same \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///home/sydney/.local/lib/python3.8/site-packages/tensorflow/python/ops/variable_scope.py?line=528'>529</a>\u001b[0m       \u001b[39m\"\u001b[39m\u001b[39mname was already created with partitioning?\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m name)\n\u001b[0;32m--> <a href='file:///home/sydney/.local/lib/python3.8/site-packages/tensorflow/python/ops/variable_scope.py?line=530'>531</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_single_variable(\n\u001b[1;32m    <a href='file:///home/sydney/.local/lib/python3.8/site-packages/tensorflow/python/ops/variable_scope.py?line=531'>532</a>\u001b[0m     name\u001b[39m=\u001b[39;49mname,\n\u001b[1;32m    <a href='file:///home/sydney/.local/lib/python3.8/site-packages/tensorflow/python/ops/variable_scope.py?line=532'>533</a>\u001b[0m     shape\u001b[39m=\u001b[39;49mshape,\n\u001b[1;32m    <a href='file:///home/sydney/.local/lib/python3.8/site-packages/tensorflow/python/ops/variable_scope.py?line=533'>534</a>\u001b[0m     dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[1;32m    <a href='file:///home/sydney/.local/lib/python3.8/site-packages/tensorflow/python/ops/variable_scope.py?line=534'>535</a>\u001b[0m     initializer\u001b[39m=\u001b[39;49minitializer,\n\u001b[1;32m    <a href='file:///home/sydney/.local/lib/python3.8/site-packages/tensorflow/python/ops/variable_scope.py?line=535'>536</a>\u001b[0m     regularizer\u001b[39m=\u001b[39;49mregularizer,\n\u001b[1;32m    <a href='file:///home/sydney/.local/lib/python3.8/site-packages/tensorflow/python/ops/variable_scope.py?line=536'>537</a>\u001b[0m     reuse\u001b[39m=\u001b[39;49mreuse,\n\u001b[1;32m    <a href='file:///home/sydney/.local/lib/python3.8/site-packages/tensorflow/python/ops/variable_scope.py?line=537'>538</a>\u001b[0m     trainable\u001b[39m=\u001b[39;49mtrainable,\n\u001b[1;32m    <a href='file:///home/sydney/.local/lib/python3.8/site-packages/tensorflow/python/ops/variable_scope.py?line=538'>539</a>\u001b[0m     collections\u001b[39m=\u001b[39;49mcollections,\n\u001b[1;32m    <a href='file:///home/sydney/.local/lib/python3.8/site-packages/tensorflow/python/ops/variable_scope.py?line=539'>540</a>\u001b[0m     caching_device\u001b[39m=\u001b[39;49mcaching_device,\n\u001b[1;32m    <a href='file:///home/sydney/.local/lib/python3.8/site-packages/tensorflow/python/ops/variable_scope.py?line=540'>541</a>\u001b[0m     validate_shape\u001b[39m=\u001b[39;49mvalidate_shape,\n\u001b[1;32m    <a href='file:///home/sydney/.local/lib/python3.8/site-packages/tensorflow/python/ops/variable_scope.py?line=541'>542</a>\u001b[0m     use_resource\u001b[39m=\u001b[39;49muse_resource,\n\u001b[1;32m    <a href='file:///home/sydney/.local/lib/python3.8/site-packages/tensorflow/python/ops/variable_scope.py?line=542'>543</a>\u001b[0m     constraint\u001b[39m=\u001b[39;49mconstraint,\n\u001b[1;32m    <a href='file:///home/sydney/.local/lib/python3.8/site-packages/tensorflow/python/ops/variable_scope.py?line=543'>544</a>\u001b[0m     synchronization\u001b[39m=\u001b[39;49msynchronization,\n\u001b[1;32m    <a href='file:///home/sydney/.local/lib/python3.8/site-packages/tensorflow/python/ops/variable_scope.py?line=544'>545</a>\u001b[0m     aggregation\u001b[39m=\u001b[39;49maggregation)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/ops/variable_scope.py:894\u001b[0m, in \u001b[0;36m_VariableStore._get_single_variable\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, partition_info, reuse, trainable, collections, caching_device, validate_shape, use_resource, constraint, synchronization, aggregation)\u001b[0m\n\u001b[1;32m    <a href='file:///home/sydney/.local/lib/python3.8/site-packages/tensorflow/python/ops/variable_scope.py?line=888'>889</a>\u001b[0m   \u001b[39m# Throw away internal tf entries and only take a few lines. In some\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/sydney/.local/lib/python3.8/site-packages/tensorflow/python/ops/variable_scope.py?line=889'>890</a>\u001b[0m   \u001b[39m# cases the traceback can be longer (e.g. if someone uses factory\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/sydney/.local/lib/python3.8/site-packages/tensorflow/python/ops/variable_scope.py?line=890'>891</a>\u001b[0m   \u001b[39m# functions to create variables) so we take more than needed in the\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/sydney/.local/lib/python3.8/site-packages/tensorflow/python/ops/variable_scope.py?line=891'>892</a>\u001b[0m   \u001b[39m# default case.\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/sydney/.local/lib/python3.8/site-packages/tensorflow/python/ops/variable_scope.py?line=892'>893</a>\u001b[0m   tb \u001b[39m=\u001b[39m [x \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m tb \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mtensorflow/python\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m x[\u001b[39m0\u001b[39m]][:\u001b[39m5\u001b[39m]\n\u001b[0;32m--> <a href='file:///home/sydney/.local/lib/python3.8/site-packages/tensorflow/python/ops/variable_scope.py?line=893'>894</a>\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m Originally defined at:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m\n\u001b[1;32m    <a href='file:///home/sydney/.local/lib/python3.8/site-packages/tensorflow/python/ops/variable_scope.py?line=894'>895</a>\u001b[0m                    (err_msg, \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(traceback\u001b[39m.\u001b[39mformat_list(tb))))\n\u001b[1;32m    <a href='file:///home/sydney/.local/lib/python3.8/site-packages/tensorflow/python/ops/variable_scope.py?line=895'>896</a>\u001b[0m found_var \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_vars[name]\n\u001b[1;32m    <a href='file:///home/sydney/.local/lib/python3.8/site-packages/tensorflow/python/ops/variable_scope.py?line=896'>897</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m shape\u001b[39m.\u001b[39mis_compatible_with(found_var\u001b[39m.\u001b[39mget_shape()):\n",
      "\u001b[0;31mValueError\u001b[0m: Variable yolo_v3_model/conv2d/kernel already exists, disallowed. Did you mean to set reuse=True or reuse=tf.AUTO_REUSE in VarScope? Originally defined at:\n\n  File \"/home/sydney/.local/lib/python3.8/site-packages/keras/engine/base_layer_v1.py\", line 423, in add_weight\n    variable = self._add_variable_with_custom_getter(\n  File \"/home/sydney/.local/lib/python3.8/site-packages/keras/legacy_tf_layers/base.py\", line 456, in add_weight\n    variable = super(Layer, self).add_weight(\n  File \"/home/sydney/.local/lib/python3.8/site-packages/keras/layers/convolutional.py\", line 199, in build\n    self.kernel = self.add_weight(\n  File \"/home/sydney/.local/lib/python3.8/site-packages/keras/engine/base_layer_v1.py\", line 2072, in _maybe_build\n    self.build(input_shapes)\n  File \"/home/sydney/.local/lib/python3.8/site-packages/keras/engine/base_layer_v1.py\", line 745, in __call__\n    self._maybe_build(inputs)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "batch_size = len(img_names)\n",
    "batch = load_images(img_names, model_size=_MODEL_SIZE)\n",
    "class_names = load_class_names('../../Keras_YOLO/darknet/custom/custom.names')\n",
    "n_classes = len(class_names)\n",
    "max_out_size = 10\n",
    "iou_threshold = 0.5\n",
    "confidence_threshold = 0.5\n",
    "\n",
    "model = Yolo_v3(n_classes=n_classes, model_size=_MODEL_SIZE, max_output_size=max_out_size,\n",
    "                iou_threshold=iou_threshold, confidence_threshold=confidence_threshold)\n",
    "\n",
    "inputs = tf.placeholder(tf.float32, [batch_size, 416, 416, 3])\n",
    "\n",
    "detections = model(inputs, training=False)\n",
    "\n",
    "model_vars = tf.global_variables(scope=\"../../Keras_YOLO/darknet/darknet53.conv.74\")\n",
    "assign_ops = load_weights(model_vars, \"../../Keras_YOLO/darknet/custom/darknet53.weights\")\n",
    "\n",
    "with tf.Session() as sess:\n",
    "      sess.run(assign_ops)\n",
    "      detection_result = sess.run(detections, feed_dict={inputs: batch})\n",
    "      \n",
    "draw_boxes(img_names, detection_result, class_names, _MODEL_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4e5aabf685a30631e3d6236dff8b3ac5a6d3107c1574662e0e1864020afd59eb"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('selfstudy_venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
